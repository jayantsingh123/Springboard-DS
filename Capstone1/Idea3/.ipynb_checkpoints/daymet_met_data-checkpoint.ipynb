{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"..\")\n",
    "\n",
    "import daymetpy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import descartes\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "from shapely.ops import nearest_points\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import math\n",
    "\n",
    "from matplotlib import cm\n",
    "\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "import netCDF4 as nc\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading EDF monitoring data to get location of measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_measured = pd.read_csv('EDF_Data.csv', header = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting only the latitude and longitude\n",
    "df_measured = df_measured[['Latitude','Longitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21488, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_measured.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Defining a function that takes each latitude and longitude as inputs, and calculates average parameters between Jun 2015 - May 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_1, long_1 = 37.806781,-122.322594\n",
    "df = daymetpy.daymet_timeseries(lon=long_1, lat=lat_1, start_year=2015, end_year=2016, as_dataframe=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'index':'Datestamp'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['Datestamp']>= '2015-06-01') & (df['Datestamp'] <= '2016-05-31')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= np.mean(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daymet_avg(df1, year1, year2):\n",
    "    df1.reset_index(inplace=True) #Reset index such that we have a column as YYYY-MM-DD\n",
    "    df1.rename(columns={'index':'Datestamp'}, inplace=True) #Rename index as Datestamp\n",
    "    start_date = str(year1) + '-06-01'\n",
    "    end_date = str(year2) + '-05-31'\n",
    "    df1 = df1[(df1['Datestamp']>= start_date) & (df1['Datestamp'] <= end_date)] # Filter for days only between June 2015 to May 2016\n",
    "    df1.drop(columns=['swe'], inplace = True) #Drop snow water equivalent since its always zero in Oakland\n",
    "    df1_avg = np.mean(df1)\n",
    "    return (df1_avg['dayl'],df1_avg['prcp'],df1_avg['srad'], df1_avg['tmax'] ,df1_avg['tmin'] ,df1_avg['vp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_met_average_data = []\n",
    "start_year = 2015\n",
    "end_year = 2016\n",
    "for row in df_measured.head(2).iterrows():\n",
    "    lon, lat = (row[1]['Longitude'], row[1]['Latitude'])\n",
    "    daymet_raw_df = daymetpy.daymet_timeseries(lon=lon, lat=lat, start_year=start_year, end_year=end_year, as_dataframe=True)\n",
    "    daily_met_average_data.append(daymet_avg(daymet_raw_df, start_year, end_year)) ## create a list with daymet parameters for each location\n",
    "\n",
    "compute_daily_met_average_df = pd.DataFrame(daily_met_average_data) #convert list to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the latitude and longitude from df_measured to the daymet_average dataframe\n",
    "daymet_average = daymet_average.join(df_measured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write to a csv file\n",
    "daymet_average.to_csv(\"Data/daymet_avg_15_16.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
